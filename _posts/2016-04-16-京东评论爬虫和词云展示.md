## 写在前面

这本是数据挖掘课上老师布置的作业，做完后便记录在这里。作业的要求是：利用爬虫抓取文本数据，进行文本分词，对分词后的数据进行高频词排名，并绘制词云。  

正巧自己最近在啃周志华老师的《机器学习》，所以，就决定爬京东上这本书的评论来做这个作业。   

## 爬虫

爬虫和清理数据用的的R中的RCurl包和XML包

​		library(XML)

​		library(RCurl)

京东的评论网址一般是这样的：http://club.jd.com/review/11867803-1-1-0.html在抓取的时候，遇到的问题是：循环中每抓20页之后就报错，猜测应该是京东设置了什么反爬虫的机制吧。我的解决办法是暴力解决，不让抓就不停地抓，一直抓到为止，用了R中的try函数。



